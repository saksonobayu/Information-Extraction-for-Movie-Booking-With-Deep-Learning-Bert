{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled10.ipynb","provenance":[],"authorship_tag":"ABX9TyOIqsDJWqEHzCasIEjkVAcf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"b9e3ddb1ebd74d1c80dff47a56a41d49":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c01a2c6b6c534062a56395c98b5f24da","IPY_MODEL_afc41bb845ff461f9574fd7ae3e6ab15","IPY_MODEL_5c0947e05b864ef790d9ec1cb17a49be"],"layout":"IPY_MODEL_20015830c699475bb746cd8889d58469"}},"c01a2c6b6c534062a56395c98b5f24da":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c65c0408136340fa96a057ac92d729e3","placeholder":"​","style":"IPY_MODEL_8234eb33348a42cb9097f8bc85960407","value":"Downloading: 100%"}},"afc41bb845ff461f9574fd7ae3e6ab15":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8668080053134ba69e914723870adeef","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9417df268ef74d3fa999b2ef79be2de4","value":29}},"5c0947e05b864ef790d9ec1cb17a49be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c805b5e5ba04a31bd1711ecc8959777","placeholder":"​","style":"IPY_MODEL_3c90268f8b5c4a2a996ea3f59d74d057","value":" 29.0/29.0 [00:00&lt;00:00, 556B/s]"}},"20015830c699475bb746cd8889d58469":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c65c0408136340fa96a057ac92d729e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8234eb33348a42cb9097f8bc85960407":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8668080053134ba69e914723870adeef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9417df268ef74d3fa999b2ef79be2de4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c805b5e5ba04a31bd1711ecc8959777":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c90268f8b5c4a2a996ea3f59d74d057":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2f7be5729aa94178821bc5e4d46d4094":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_477b11a91efb4d16b1d8668630f41ac4","IPY_MODEL_d576347ecc324e6c8392648e9dd9ab9c","IPY_MODEL_3c1a2bc029b04a50abdddf22d5c4ce48"],"layout":"IPY_MODEL_200db761bb894b3a8e2610e13289a36d"}},"477b11a91efb4d16b1d8668630f41ac4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b33c3d6305fc4c3ab0ec25ed428461d9","placeholder":"​","style":"IPY_MODEL_e2c8b766a5554a2890f0ba904d395a8a","value":"Downloading: 100%"}},"d576347ecc324e6c8392648e9dd9ab9c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_749a7257669a4b34a67f691396d46872","max":213450,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ceedee176f6a4bf9a285bf07459226d7","value":213450}},"3c1a2bc029b04a50abdddf22d5c4ce48":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_686d1e30c396487494dbafd8336d410d","placeholder":"​","style":"IPY_MODEL_63d683acc73a4578a92312d1d947158a","value":" 208k/208k [00:00&lt;00:00, 876kB/s]"}},"200db761bb894b3a8e2610e13289a36d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b33c3d6305fc4c3ab0ec25ed428461d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2c8b766a5554a2890f0ba904d395a8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"749a7257669a4b34a67f691396d46872":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ceedee176f6a4bf9a285bf07459226d7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"686d1e30c396487494dbafd8336d410d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"63d683acc73a4578a92312d1d947158a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"993333fe35164ddf83a8675363c0ea11":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6548446cc3bf4303ba54222777787ee8","IPY_MODEL_904c5ef4bb784d34af2b7b2e1090d8eb","IPY_MODEL_6f8cae33793e4ca997f3e389630b85dc"],"layout":"IPY_MODEL_af4d59d068064fd18f8548044510e124"}},"6548446cc3bf4303ba54222777787ee8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_62798044e64146d99a2d69680713d220","placeholder":"​","style":"IPY_MODEL_4230517dc92847f1bacae7db015a21cd","value":"Downloading: 100%"}},"904c5ef4bb784d34af2b7b2e1090d8eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d594e9d471fd4a529ea7f6db4ee488f1","max":435797,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c77927dda6314ef08b77cd3ed2310200","value":435797}},"6f8cae33793e4ca997f3e389630b85dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_47dfc835aa7f433abb51577773b7d315","placeholder":"​","style":"IPY_MODEL_ed027fc9cec946699912aa5fa78b6dc0","value":" 426k/426k [00:00&lt;00:00, 929kB/s]"}},"af4d59d068064fd18f8548044510e124":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62798044e64146d99a2d69680713d220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4230517dc92847f1bacae7db015a21cd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d594e9d471fd4a529ea7f6db4ee488f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c77927dda6314ef08b77cd3ed2310200":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"47dfc835aa7f433abb51577773b7d315":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ed027fc9cec946699912aa5fa78b6dc0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["! pip install transformers # transformers library from huggingface\n","! pip install datasets # datasets library from huggingface"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3imb80QYDJ_1","executionInfo":{"status":"ok","timestamp":1656516769822,"user_tz":-420,"elapsed":7644,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}},"outputId":"4df1ee6d-efc3-4f9f-c786-a843cece8efd"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.3.2)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.5.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n","Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}]},{"cell_type":"code","source":["import os\n","import torch\n","import csv\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n","from transformers import BertTokenizerFast, BertForTokenClassification, Trainer, TrainingArguments\n","\n","# Define the available device.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","torch.device(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7jf19lQcDPlJ","executionInfo":{"status":"ok","timestamp":1656524020887,"user_tz":-420,"elapsed":522,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}},"outputId":"3ce91226-c146-4070-caa3-2d6c9d0aa980"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":72}]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJWY0KEN9M83","executionInfo":{"status":"ok","timestamp":1656516774907,"user_tz":-420,"elapsed":38,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}},"outputId":"c213bcfd-d5fe-4243-92cb-5d198dc9b434"},"outputs":[{"output_type":"stream","name":"stdout","text":["fatal: destination path 'MIT_movies_fixed' already exists and is not an empty directory.\n"]}],"source":["# git lfs install\n","!git clone https://huggingface.co/datasets/rungalileo/MIT_movies_fixed"]},{"cell_type":"code","source":["# Showing some examples\n","df = pd.read_csv(\"MIT_movies_fixed/MIT_movies_fixed_train.tsv\", sep=\"\\t\", header=None, quoting=csv.QUOTE_NONE)\n","df.head(60)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vUGBjdeTDc6C","executionInfo":{"status":"ok","timestamp":1656524025200,"user_tz":-420,"elapsed":590,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}},"outputId":"0bc61f93-50df-41ff-d103-5a6acca86c96"},"execution_count":73,"outputs":[{"output_type":"execute_result","data":{"text/plain":["              0        1\n","0          what        O\n","1        movies        O\n","2          star        O\n","3         bruce  B-ACTOR\n","4        willis  E-ACTOR\n","5          show        O\n","6            me        O\n","7         films        O\n","8          with        O\n","9          drew  B-ACTOR\n","10    barrymore  E-ACTOR\n","11         from        O\n","12          the        O\n","13        1980s   S-YEAR\n","14         what        O\n","15       movies        O\n","16      starred        O\n","17         both        O\n","18           al  B-ACTOR\n","19       pacino  E-ACTOR\n","20          and        O\n","21       robert  B-ACTOR\n","22       deniro  E-ACTOR\n","23         find        O\n","24           me        O\n","25          all        O\n","26           of        O\n","27          the        O\n","28       movies        O\n","29         that        O\n","30      starred        O\n","31       harold  B-ACTOR\n","32        ramis  E-ACTOR\n","33          and        O\n","34         bill  B-ACTOR\n","35       murray  E-ACTOR\n","36         find        O\n","37           me        O\n","38            a        O\n","39        movie        O\n","40         with        O\n","41            a        O\n","42        quote        O\n","43        about        O\n","44     baseball        O\n","45           in        O\n","46           it        O\n","47         what        O\n","48       movies        O\n","49         have        O\n","50  mississippi  S-TITLE\n","51           in        O\n","52          the        O\n","53        title        O\n","54         show        O\n","55           me        O\n","56      science  B-GENRE\n","57      fiction  I-GENRE\n","58        films  E-GENRE\n","59     directed        O"],"text/html":["\n","  <div id=\"df-662467fd-8611-4f2a-bab1-b3dcd98e0ac0\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>what</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>movies</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>star</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>bruce</td>\n","      <td>B-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>willis</td>\n","      <td>E-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>show</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>me</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>films</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>with</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>drew</td>\n","      <td>B-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>barrymore</td>\n","      <td>E-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>from</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>the</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>1980s</td>\n","      <td>S-YEAR</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>what</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>movies</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>starred</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>both</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>al</td>\n","      <td>B-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>pacino</td>\n","      <td>E-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>20</th>\n","      <td>and</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>21</th>\n","      <td>robert</td>\n","      <td>B-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>22</th>\n","      <td>deniro</td>\n","      <td>E-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>23</th>\n","      <td>find</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>24</th>\n","      <td>me</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>25</th>\n","      <td>all</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>26</th>\n","      <td>of</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>27</th>\n","      <td>the</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>28</th>\n","      <td>movies</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>29</th>\n","      <td>that</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>30</th>\n","      <td>starred</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>31</th>\n","      <td>harold</td>\n","      <td>B-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>32</th>\n","      <td>ramis</td>\n","      <td>E-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>33</th>\n","      <td>and</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>34</th>\n","      <td>bill</td>\n","      <td>B-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>35</th>\n","      <td>murray</td>\n","      <td>E-ACTOR</td>\n","    </tr>\n","    <tr>\n","      <th>36</th>\n","      <td>find</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>37</th>\n","      <td>me</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>38</th>\n","      <td>a</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>39</th>\n","      <td>movie</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>with</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>41</th>\n","      <td>a</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>42</th>\n","      <td>quote</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>about</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>baseball</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>in</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>it</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>what</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>movies</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>have</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>mississippi</td>\n","      <td>S-TITLE</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>in</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>the</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>title</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>show</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>me</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>science</td>\n","      <td>B-GENRE</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>fiction</td>\n","      <td>I-GENRE</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>films</td>\n","      <td>E-GENRE</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>directed</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-662467fd-8611-4f2a-bab1-b3dcd98e0ac0')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-662467fd-8611-4f2a-bab1-b3dcd98e0ac0 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-662467fd-8611-4f2a-bab1-b3dcd98e0ac0');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":73}]},{"cell_type":"code","source":["class MyPOSTaggingDataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, index):\n","        item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n","        item['labels'] = torch.tensor(self.labels[index])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.labels)"],"metadata":{"id":"xvWaGyrqDz7p","executionInfo":{"status":"ok","timestamp":1656524029215,"user_tz":-420,"elapsed":464,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}}},"execution_count":74,"outputs":[]},{"cell_type":"code","source":["def alignLabels(labels, encodedData):\n","  \"\"\"\n","  This function aligns labels with subwords because length of labels is not the same as length of encoded data (because of subwords).\n","  \"\"\"\n","  alignedLabels = []\n","\n","  for i, tags in enumerate(labels): # Loop over sentences\n","    wordIds = encodedData.word_ids(i) # get real word indices of the sentence i.\n","    previousWordId = None\n","    alignedTags = []\n","\n","    for wordId in wordIds: # Loop over tokens\n","      if wordId is None or wordId == previousWordId: # If it is special token (word id == None) or is 2nd/3rd subword.\n","        alignedTags.append(-100) # then labeled as -100.\n","      else: # If it is not special token and is 1st subword.\n","        alignedTags.append(tags[wordId]) # then labeled as usual.\n","\n","      previousWordId = wordId\n","\n","    alignedLabels.append(alignedTags)\n","\n","  return alignedLabels"],"metadata":{"id":"jkyhjPVuD4CR","executionInfo":{"status":"ok","timestamp":1656524030966,"user_tz":-420,"elapsed":11,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["def loadDataset(type, tagList):\n","  \"\"\"\n","  This function loads the dataset.\n","  type: \"train\" and \"test\".\n","  tagList: list of tag categories.\n","  \"\"\"\n","\n","  sentences = []\n","  labels = []\n","  with open(f\"MIT_movies_fixed/MIT_movies_fixed_{type}.tsv\") as lines: # Read the document.\n","    sentence = []\n","    tags = []\n","    for line in lines: # Loop over lines. One line contains a token and its tag.\n","      line = line.strip(\"\\n\") # IMPORTANT!\n","      if len(line) == 0: # If it's an end of a sentence.\n","        if len(sentence) > 0:\n","          # Pool the tokens and their labels.\n","          sentences.append(sentence)\n","          labels.append(tags)\n","        # Re-init new sentence.\n","        sentence = []\n","        tags = []\n","      else: # If it's not an end of a sentence.\n","        token, tag = line.split()\n","        # Pool a token and its label.\n","        sentence.append(token)\n","        tags.append(tagList.index(tag))\n","\n","  return sentences, labels"],"metadata":{"id":"n-IXm0_7D7wZ","executionInfo":{"status":"ok","timestamp":1656525113025,"user_tz":-420,"elapsed":557,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["trainDf = pd.read_csv(\"MIT_movies_fixed/MIT_movies_fixed_train.tsv\", sep=\"\\t\", header=None)\n","testDf = pd.read_csv(\"MIT_movies_fixed/MIT_movies_fixed_test.tsv\", sep=\"\\t\", header=None)\n","\n","# Pooling unique tags.\n","TAGSET = set()\n","for key, rows in trainDf.iterrows():\n","  TAGSET.add(rows[1])\n","\n","for key, rows in testDf.iterrows():\n","  TAGSET.add(rows[1])\n","\n","TAGLIST = list(TAGSET)\n","print(TAGLIST)\n","print(len(TAGLIST), \"tags\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KtDarDapFYtB","executionInfo":{"status":"ok","timestamp":1656525344473,"user_tz":-420,"elapsed":6260,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}},"outputId":"8e1415c9-faf0-434a-e1f4-60e6ea785c02"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["[nan, 'S-RATINGS_AVERAGE', 'I-SONG', 'I-PLOT', 'S-CHARACTER', 'E-YEAR', 'I-GENRE', 'I-TRAILER', 'S-RATING', 'E-CHARACTER', 'B-GENRE', 'B-REVIEW', 'E-SONG', 'B-DIRECTOR', 'E-TRAILER', 'E-REVIEW', 'E-GENRE', 'E-RATING', 'S-PLOT', 'I-TITLE', 'S-YEAR', 'I-RATINGS_AVERAGE', 'I-RATING', 'I-CHARACTER', 'B-PLOT', 'I-REVIEW', 'S-SONG', 'I-DIRECTOR', 'E-RATINGS_AVERAGE', 'I-ACTOR', 'E-DIRECTOR', 'S-REVIEW', 'B-RATING', 'B-ACTOR', 'E-TITLE', 'E-PLOT', 'B-TRAILER', 'S-DIRECTOR', 'S-ACTOR', 'E-ACTOR', 'B-YEAR', 'I-YEAR', 'B-TITLE', 'B-SONG', 'S-TITLE', 'B-CHARACTER', 'S-GENRE', 'S-TRAILER', 'B-RATINGS_AVERAGE', 'O']\n","50 tags\n"]}]},{"cell_type":"code","source":["trainSentences, trainLabels =  loadDataset(\"train\", TAGLIST)\n","testSentences, testLabels =  loadDataset(\"test\", TAGLIST)\n","\n","print(trainSentences[0])\n","print(trainLabels[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zF2z5bTyGMqF","executionInfo":{"status":"ok","timestamp":1656525452226,"user_tz":-420,"elapsed":1136,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}},"outputId":"f7cc2bcf-da82-4f52-c4a3-25b26fc0eca3"},"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["['what', 'movies', 'star', 'bruce', 'willis']\n","[49, 49, 49, 33, 39]\n"]}]},{"cell_type":"code","source":["tokenizer = BertTokenizerFast.from_pretrained('bert-base-cased')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["b9e3ddb1ebd74d1c80dff47a56a41d49","c01a2c6b6c534062a56395c98b5f24da","afc41bb845ff461f9574fd7ae3e6ab15","5c0947e05b864ef790d9ec1cb17a49be","20015830c699475bb746cd8889d58469","c65c0408136340fa96a057ac92d729e3","8234eb33348a42cb9097f8bc85960407","8668080053134ba69e914723870adeef","9417df268ef74d3fa999b2ef79be2de4","8c805b5e5ba04a31bd1711ecc8959777","3c90268f8b5c4a2a996ea3f59d74d057","2f7be5729aa94178821bc5e4d46d4094","477b11a91efb4d16b1d8668630f41ac4","d576347ecc324e6c8392648e9dd9ab9c","3c1a2bc029b04a50abdddf22d5c4ce48","200db761bb894b3a8e2610e13289a36d","b33c3d6305fc4c3ab0ec25ed428461d9","e2c8b766a5554a2890f0ba904d395a8a","749a7257669a4b34a67f691396d46872","ceedee176f6a4bf9a285bf07459226d7","686d1e30c396487494dbafd8336d410d","63d683acc73a4578a92312d1d947158a","993333fe35164ddf83a8675363c0ea11","6548446cc3bf4303ba54222777787ee8","904c5ef4bb784d34af2b7b2e1090d8eb","6f8cae33793e4ca997f3e389630b85dc","af4d59d068064fd18f8548044510e124","62798044e64146d99a2d69680713d220","4230517dc92847f1bacae7db015a21cd","d594e9d471fd4a529ea7f6db4ee488f1","c77927dda6314ef08b77cd3ed2310200","47dfc835aa7f433abb51577773b7d315","ed027fc9cec946699912aa5fa78b6dc0"]},"id":"R1GeSBojYIir","executionInfo":{"status":"ok","timestamp":1656526702694,"user_tz":-420,"elapsed":4212,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}},"outputId":"d05919cf-5fb0-4edd-eaac-9f730f225c80"},"execution_count":103,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9e3ddb1ebd74d1c80dff47a56a41d49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/208k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f7be5729aa94178821bc5e4d46d4094"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/426k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"993333fe35164ddf83a8675363c0ea11"}},"metadata":{}}]},{"cell_type":"code","source":["trainEncodings = tokenizer(trainSentences, is_split_into_words=True, padding=True)\n","testEncodings = tokenizer(testSentences, is_split_into_words=True, padding=True)\n","\n","# Aligning labels with subwords.\n","trainLabels = alignLabels(trainLabels, trainEncodings)\n","testLabels = alignLabels(testLabels, testEncodings)"],"metadata":{"id":"GjokUrdLampD","executionInfo":{"status":"ok","timestamp":1656527756209,"user_tz":-420,"elapsed":2373,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}}},"execution_count":106,"outputs":[]},{"cell_type":"code","source":["trainDataset = MyPOSTaggingDataset(trainEncodings, trainLabels)\n","testDataset = MyPOSTaggingDataset(testEncodings, testLabels)"],"metadata":{"id":"senjJ9LEv7no","executionInfo":{"status":"ok","timestamp":1656527803520,"user_tz":-420,"elapsed":442,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}}},"execution_count":107,"outputs":[]},{"cell_type":"code","source":["# Loading the model.\n","model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(TAGSET))\n","model.to(device) # Send to GPU if available.\n","# Pay attention on the log messege:\n","# \"Some weights of BertForTokenClassification were not initialized from the model checkpoint and are newly initialized.\"\n","# \"You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\"\n","# It means that this model is not ready to use and needs fine-tuning.\n","print()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yb8mnqzwwK3l","executionInfo":{"status":"ok","timestamp":1656527900561,"user_tz":-420,"elapsed":2942,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}},"outputId":"73030d35-48b5-4894-ef7b-4baddcdf3ea7"},"execution_count":109,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"stream","name":"stdout","text":["\n"]}]},{"cell_type":"code","source":["# Print the architecture\n","model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SiG1i6zRwoAy","executionInfo":{"status":"ok","timestamp":1656527951337,"user_tz":-420,"elapsed":410,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}},"outputId":"87bf76b4-e62f-46bd-a7fe-8d6d7f3c8dc0"},"execution_count":110,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForTokenClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(28996, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=50, bias=True)\n",")"]},"metadata":{},"execution_count":110}]},{"cell_type":"code","source":["# https://huggingface.co/docs/transformers/master/en/main_classes/trainer#transformers.TrainingArguments\n","trainingArgs = TrainingArguments(\n","  output_dir = \"MIT_movies_fixed_checkpoints\",\n","  evaluation_strategy = \"epoch\",\n","  logging_strategy = \"epoch\",\n","  save_strategy = \"epoch\",\n","  overwrite_output_dir = True,\n","  per_device_train_batch_size = 16, # 16 or 32 is recommended.\n","  per_device_eval_batch_size = 1,\n","  learning_rate = 2e-5, # 5e-5, 2e-5, or 1e-5 is recommended.\n","  weight_decay = 0.01, # 0, 0.01, 0.05, 0.1, 0.15, or 0.2.\n","  num_train_epochs = 4,\n","  logging_steps = 1, # To print training loss in each epoch.\n","  load_best_model_at_end = True,\n","  metric_for_best_model = \"f1\",\n","  greater_is_better = True,\n",")\n","\n","def computeMetrics(evalPreds):\n","  predictions, labels = evalPreds\n","  predictions = np.argmax(predictions, axis=2)\n","\n","  # Removing predictions that correspond to label -100.\n","  cleanPreds = []\n","  cleanLabels = []\n","  for pred, label in zip(predictions, labels): # Loop over sentences.\n","    for p, l in zip(pred, label): # Loop over tokens.\n","      if l != -100: # If not -100, then pool.\n","        cleanPreds.append(p)\n","        cleanLabels.append(l)\n","\n","  accuracy = accuracy_score(cleanLabels, cleanPreds)\n","  precision = precision_score(cleanLabels, cleanPreds, average=\"macro\")\n","  recall = recall_score(cleanLabels, cleanPreds, average=\"macro\")\n","  f1Score = f1_score(cleanLabels, cleanPreds, average=\"macro\")\n","\n","  return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1Score}\n","\n","# https://huggingface.co/docs/transformers/master/en/main_classes/trainer\n","trainer = Trainer(\n","  model = model,\n","  args = trainingArgs,\n","  train_dataset = trainDataset,\n","  eval_dataset = testDataset,\n","  compute_metrics = computeMetrics,\n","  # The default optimizer used by the trainer is AdamW. So, no need to specify.\n","  # If you want to change the optimizer, please read https://huggingface.co/docs/transformers/main_classes/trainer#transformers.Trainer.optimizers .\n",")\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"jLMYz3S5wpGK","executionInfo":{"status":"ok","timestamp":1656555919484,"user_tz":-420,"elapsed":13882916,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}},"outputId":"fa388bae-3acd-4fd4-98b9-9f2e15b5798a"},"execution_count":111,"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  FutureWarning,\n","***** Running training *****\n","  Num examples = 9774\n","  Num Epochs = 4\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 2444\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='1239' max='2444' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1239/2444 3:52:32 < 3:46:31, 0.09 it/s, Epoch 2.03/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.559100</td>\n","      <td>0.305919</td>\n","      <td>0.937832</td>\n","      <td>0.647339</td>\n","      <td>0.585156</td>\n","      <td>0.605674</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.214000</td>\n","      <td>0.271524</td>\n","      <td>0.944195</td>\n","      <td>0.650643</td>\n","      <td>0.615661</td>\n","      <td>0.629625</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["***** Running Evaluation *****\n","  Num examples = 2442\n","  Batch size = 1\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Saving model checkpoint to MIT_movies_fixed_checkpoints/checkpoint-611\n","Configuration saved in MIT_movies_fixed_checkpoints/checkpoint-611/config.json\n","Model weights saved in MIT_movies_fixed_checkpoints/checkpoint-611/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 2442\n","  Batch size = 1\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Saving model checkpoint to MIT_movies_fixed_checkpoints/checkpoint-1222\n","Configuration saved in MIT_movies_fixed_checkpoints/checkpoint-1222/config.json\n","Model weights saved in MIT_movies_fixed_checkpoints/checkpoint-1222/pytorch_model.bin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='2444' max='2444' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [2444/2444 7:44:01, Epoch 4/4]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.559100</td>\n","      <td>0.305919</td>\n","      <td>0.937832</td>\n","      <td>0.647339</td>\n","      <td>0.585156</td>\n","      <td>0.605674</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.214000</td>\n","      <td>0.271524</td>\n","      <td>0.944195</td>\n","      <td>0.650643</td>\n","      <td>0.615661</td>\n","      <td>0.629625</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.158400</td>\n","      <td>0.266187</td>\n","      <td>0.946545</td>\n","      <td>0.679418</td>\n","      <td>0.640058</td>\n","      <td>0.652146</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.128200</td>\n","      <td>0.263117</td>\n","      <td>0.947112</td>\n","      <td>0.682068</td>\n","      <td>0.648247</td>\n","      <td>0.658057</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 2442\n","  Batch size = 1\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Saving model checkpoint to MIT_movies_fixed_checkpoints/checkpoint-1833\n","Configuration saved in MIT_movies_fixed_checkpoints/checkpoint-1833/config.json\n","Model weights saved in MIT_movies_fixed_checkpoints/checkpoint-1833/pytorch_model.bin\n","***** Running Evaluation *****\n","  Num examples = 2442\n","  Batch size = 1\n","/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","Saving model checkpoint to MIT_movies_fixed_checkpoints/checkpoint-2444\n","Configuration saved in MIT_movies_fixed_checkpoints/checkpoint-2444/config.json\n","Model weights saved in MIT_movies_fixed_checkpoints/checkpoint-2444/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from MIT_movies_fixed_checkpoints/checkpoint-2444 (score: 0.6580568786206757).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=2444, training_loss=0.2649374991509021, metrics={'train_runtime': 27852.005, 'train_samples_per_second': 1.404, 'train_steps_per_second': 0.088, 'total_flos': 1177705826488800.0, 'train_loss': 0.2649374991509021, 'epoch': 4.0})"]},"metadata":{},"execution_count":111}]},{"cell_type":"code","source":["text = \"there any good romantic comedies out right now\"\n","# text = \"what movies star bruce willis show me films with drew barrymore from the 1980s\"\n","encodedData = tokenizer(text, return_tensors=\"pt\")\n","encodedData.to(device)\n","\n","model.eval() # IMPORTANT! Set the model as evaluation mode.\n","with torch.no_grad(): # IMPORTANT! Do not computing gradient!\n","  outputs = model(encodedData[\"input_ids\"], attention_mask=encodedData[\"attention_mask\"]) # Feed forward. Without calculating loss.\n","\n","logits = outputs.logits.detach().cpu() # Getting logits, moving to CPU.\n","predictions = torch.argmax(logits, dim=2).numpy() # Getting most probable prediction.\n","predictions = list(predictions[0])\n","print(\"Predictions: \", predictions)\n","\n","wordIndices = encodedData.word_ids()\n","print(\"Word Indices: \", wordIndices)\n","\n","subwords = tokenizer.convert_ids_to_tokens(encodedData[\"input_ids\"].tolist()[0])\n","print(\"Subwords: \", subwords)\n","print()\n","\n","lastWordIndex = None\n","lastWord = None\n","lastTag = None\n","for index, (wordIndex, subword, tagIndex) in enumerate(zip(wordIndices, subwords, predictions)):\n","  if index == 0:\n","    continue\n","\n","  if lastWordIndex == wordIndex:\n","    if subword.startswith(\"##\"):\n","      subword = subword[2:]\n","    lastWord += subword\n","  else:\n","    if lastWord != None:\n","      print(lastWord, lastTag)\n","    lastWord = subword\n","    lastTag = TAGLIST[tagIndex]\n","\n","  lastWordIndex = wordIndex"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dkf8dAs2sBr5","executionInfo":{"status":"ok","timestamp":1656556012613,"user_tz":-420,"elapsed":402,"user":{"displayName":"Ramdon Baehaki","userId":"08673502646022069732"}},"outputId":"76df1a14-c3f2-42d1-d386-3f12c716fb43"},"execution_count":112,"outputs":[{"output_type":"stream","name":"stdout","text":["Predictions:  [49, 49, 49, 49, 10, 16, 49, 49, 49, 49]\n","Word Indices:  [None, 0, 1, 2, 3, 4, 5, 6, 7, None]\n","Subwords:  ['[CLS]', 'there', 'any', 'good', 'romantic', 'comedies', 'out', 'right', 'now', '[SEP]']\n","\n","there O\n","any O\n","good O\n","romantic B-GENRE\n","comedies E-GENRE\n","out O\n","right O\n","now O\n"]}]}]}